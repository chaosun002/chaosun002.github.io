---
layout: page
title: 研究
permalink: /research/
---

<font size="+2">  <strong>期刊论文 </strong>
 </font><br>
<a href="https://chaosun002.github.io/research/">Nash Equilibrium Seeking with Prescribed Performance</a><br>作者 Chao Sun, Guoqiang Hu<br><u><i>Control Theory and Technology</i></u>, 已录用<br>
<p style="text-align:justify">  
 <i>简介：In this work, we study a Nash Equilibrium (NE) seeking problem for strongly monotone non-cooperative games with prescribed performance. Unlike general NE seeking algorithms, the proposed prescribed-performance NE seeking laws ensure that the convergence error evolves within a predefined region. Thus, the settling time, convergence rate, and maximum overshoot of the algorithm can be guaranteed. First, we develop a second-order Newton-like algorithm that can guarantee prescribed performance and asymptotically converge to the NE of the game. Then, we develop a first-order gradient-based algorithm. To remove some restrictions on this first-order algorithm, we propose two discontinuous dynamical system-based algorithms using tools from non-smooth analysis and adaptive control. We study the special case in optimization problems. Then, we investigate the robustness of the algorithms. It can be proven that the proposed algorithms can guarantee asymptotic convergence to the Nash equilibrium with prescribed performance in the presence of bounded disturbances. Furthermore, we consider a second-order dynamical system solution. The simulation results verify the effectiveness and efficiency of the algorithms, in terms of their convergence rate and disturbance rejection ability.</p><br>
<br>
 <a href="https://ieeexplore.ieee.org/abstract/document/9376701">Time-varying Optimization-based Approach for Distributed Formation of Uncertain Euler–Lagrange Systems</a> 
 <br>作者 Chao Sun, Zhi Feng, Guoqiang Hu<br><u><i>IEEE Transactions on Cybernetics</i></u>, 52 (7), 5984-5998, 2022<br>
<p style="text-align:justify">  
 <i>简介：We investigate a distributed time-varying formation control problem for an uncertain Euler–Lagrange system. A time-varying optimization-based approach is proposed. Based on this approach, the robots can achieve the expected formation configuration and meanwhile optimize a global objective function using only neighboring and local information. We consider the time-varying optimization where the objective functions can change in real time. In this case, the consensus-based formation tracking control issues and formation containment tracking control issues in the literature can be solved by the proposed approach. By a penalty-based method, the robots’states asymptotically converge to the estimated optimal solution to an equivalent time-varying optimization problem, whose optimal solution can achieve simultaneous formation and optimization. Furthermore, we consider two more general scenarios: 1) the local objective functions can have non-neighbor’s information and 2) the optimization problems can have inequality constraints.</p>
<br>
 <a href="https://ieeexplore.ieee.org/document/9514500">Distributed Generalized Nash Equilibrium Seeking for Monotone Generalized Noncooperative Games by a Regularized Penalized Dynamical System</a> 
 <br>作者 Chao Sun, Guoqiang Hu<br><u><i>IEEE Transactions on Cybernetics</i></u>, 51 (11), 5532-5545, 2021<br>
<p style="text-align:justify">  
 <i>简介：In this work, we study the generalized Nash equilibrium (GNE) seeking problem for monotone generalized noncooperative games with set constraints and shared affine inequality constraints. A novel projected gradient-based regularized penalized dynamical system is proposed to solve this issue. The idea is to use a differentiable penalty function with a time-varying penalty parameter to deal with the inequality constraints. A time-varying regularization term is used to deal with the ill-poseness caused by the monotonicity assumption and the time-varying penalty term. The proposed dynamical system extends the regularized dynamical system in the literature to the projected gradient-based regularized penalized dynamical system, which can be used to solve generalized noncooperative games with set constraints and coupled constraints. Furthermore, we propose a distributed algorithm by using leader-following consensus, where the players have access to neighboring information only. For both cases, the asymptotic convergence to the least-norm variational equilibrium of the game is proven. Numerical examples show the effectiveness and efficiency of the proposed algorithms.</p><br>
<br>
 <a href="https://ieeexplore.ieee.org/document/9269361">Continuous-time Penalty Methods for Nash Equilibrium Seeking of
        A Nonsmooth Generalized Noncooperative Game</a>
 <br>作者 Chao Sun, Guoqiang Hu<br><u><i>IEEE Transactions on Automatic Control</i></u>, 66 (10), 4895-4902, 2021<br>
<p style="text-align:justify">  
 <i>简介：In this article, we propose centralized and distributed continuous-time penalty methods to find a Nash equilibrium for a generalized noncooperative game with shared inequality and equality constraints and private inequality constraints that depend on the player itself. By using the ℓ1 penalty function, we prove that the equilibrium of a differential inclusion is a normalized Nash equilibrium of the original generalized noncooperative game, and the centralized differential inclusion exponentially converges to the unique normalized Nash equilibrium of a strongly monotone game. Suppose that the players can communicate with their neighboring players only and the communication topology can be represented by a connected undirected graph. Based on a leader-following consensus scheme and singular perturbation techniques, we propose distributed algorithms by using the exact ℓ1 penalty function and the continuously differentiable squared ℓ2 penalty function, respectively. The squared ℓ2 penalty function method works for games with smooth constraints and the exact ℓ1 penalty function works for certain scenarios. The proposed two distributed algorithms converge to an η -neighborhood of the unique normalized Nash equilibrium and an η -neighborhood of an approximated Nash equilibrium, respectively, with η being a positive constant. For each η>0 and each initial condition, there exists an ε∗ such that for each 0<ε<ε∗ , the convergence can be guaranteed where ε is a parameter in the algorithm.</p><br>
<br>
